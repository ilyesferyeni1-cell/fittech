{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49c9a1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chargement de CSV\\matchs_gps.csv\n",
      "✅ Chargement de CSV\\training_gps.csv\n",
      "✅ Chargement de CSV\\wyscout_matchs.csv\n",
      "✅ Chargement de CSV\\wyscout_players_goalkeeper.csv\n",
      "✅ Chargement de CSV\\wyscout_players_outfield.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ============================\n",
    "# 1) Chemin du dossier CSV\n",
    "# ============================\n",
    "\n",
    "# Si ton notebook est dans \"C:/Users/Lenovo/Desktop/feryeni/\"\n",
    "# et le dossier CSV est \"C:/Users/Lenovo/Desktop/feryeni/CSV\",\n",
    "# alors ça suffit :\n",
    "DATA_DIR = Path(\"CSV\")\n",
    "\n",
    "# Sinon, mets le chemin complet :\n",
    "# DATA_DIR = Path(r\"C:\\Users\\Lenovo\\Desktop\\feryeni\\CSV\")\n",
    "\n",
    "\n",
    "def load_csv(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Charge un CSV depuis DATA_DIR avec un message clair si le fichier n'existe pas.\n",
    "    \"\"\"\n",
    "    path = DATA_DIR / filename\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"❌ Fichier introuvable : {path}\")\n",
    "    print(f\"✅ Chargement de {path}\")\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 2) Chargement des fichiers\n",
    "# ============================\n",
    "\n",
    "matches_gps   = load_csv(\"matchs_gps.csv\")\n",
    "training_gps  = load_csv(\"training_gps.csv\")\n",
    "wys_matches   = load_csv(\"wyscout_matchs.csv\")\n",
    "wys_gk        = load_csv(\"wyscout_players_goalkeeper.csv\")\n",
    "wys_outfield  = load_csv(\"wyscout_players_outfield.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462bac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddde28eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture des CSV bruts...\n",
      "✅ Chargement terminé\n",
      "matches_gps       : (2108, 812)\n",
      "training_gps      : (7903, 810)\n",
      "wyscout_matchs    : (9222, 110)\n",
      "wyscout_GK        : (15323, 20)\n",
      "wyscout_outfield  : (141558, 72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1852\\903293105.py:49: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1852\\903293105.py:49: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1852\\903293105.py:49: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] Proportion de match_key NaN dans players_wys_all : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1852\\903293105.py:49: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1852\\903293105.py:49: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Proportion de match_key NaN dans fact_match_wyscout : 0.3083929733246584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1852\\903293105.py:432: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  gps_all[\"session_date\"] = parse_date_col(gps_all[\"date\"])\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1852\\903293105.py:433: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  gps_all[\"date_key\"]     = gps_all[\"session_date\"].map(date_key_by_date)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1852\\903293105.py:434: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  gps_all[\"team_key\"]     = gps_all[\"team_name\"].map(team_key_by_name)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1852\\903293105.py:435: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  gps_all[\"player_key\"]   = gps_all[\"name\"].map(player_key_by_name)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_1852\\903293105.py:438: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  gps_all[\"match_key\"] = pd.NA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Fichiers star_schema écrits dans : CSV\\star_schema\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# =====================================================\n",
    "# 0) Chemins & chargement des CSV bruts\n",
    "# =====================================================\n",
    "\n",
    "BASE_DIR = Path(\"CSV\")\n",
    "RAW_DIR = BASE_DIR          # les CSV bruts sont directement dans CSV\n",
    "OUT_DIR = BASE_DIR / \"star_schema\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Lecture des CSV bruts...\")\n",
    "\n",
    "matches_gps   = pd.read_csv(RAW_DIR / \"matchs_gps.csv\", low_memory=False)\n",
    "training_gps  = pd.read_csv(RAW_DIR / \"training_gps.csv\", low_memory=False)\n",
    "wys_matches   = pd.read_csv(RAW_DIR / \"wyscout_matchs.csv\", low_memory=False)\n",
    "wys_gk        = pd.read_csv(RAW_DIR / \"wyscout_players_goalkeeper.csv\", low_memory=False)\n",
    "wys_outfield  = pd.read_csv(RAW_DIR / \"wyscout_players_outfield.csv\", low_memory=False)\n",
    "\n",
    "print(\"✅ Chargement terminé\")\n",
    "print(\"matches_gps       :\", matches_gps.shape)\n",
    "print(\"training_gps      :\", training_gps.shape)\n",
    "print(\"wyscout_matchs    :\", wys_matches.shape)\n",
    "print(\"wyscout_GK        :\", wys_gk.shape)\n",
    "print(\"wyscout_outfield  :\", wys_outfield.shape)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1) Fonctions utilitaires\n",
    "# =====================================================\n",
    "\n",
    "def slugify(col: str) -> str:\n",
    "    \"\"\"\n",
    "    Nettoie un nom de colonne en snake_case.\n",
    "    Utile surtout pour les tables GPS.\n",
    "    \"\"\"\n",
    "    col = str(col).strip().lower()\n",
    "    col = col.replace('%', 'pct').replace('#', 'num')\n",
    "    col = re.sub(r'[^0-9a-z]+', '_', col)\n",
    "    col = re.sub(r'_+', '_', col).strip('_')\n",
    "    return col\n",
    "\n",
    "\n",
    "def parse_date_col(s):\n",
    "    \"\"\"Parse une colonne de dates en datetime (jour/mois ou iso).\"\"\"\n",
    "    return pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "\n",
    "def make_match_uid(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Identifiant de match cohérent basé sur (match, date_parsed, competition).\n",
    "\n",
    "    - On parse la date puis on la formate en 'YYYY-MM-DD'\n",
    "    - On strip les espaces sur match / competition\n",
    "    => même clé pour toutes les tables qui ont (match, date, competition).\n",
    "    \"\"\"\n",
    "    date_parsed = parse_date_col(df[\"date\"])\n",
    "    date_str = date_parsed.dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    match_str = df[\"match\"].astype(str).str.strip()\n",
    "    comp_str  = df[\"competition\"].astype(str).str.strip()\n",
    "\n",
    "    return match_str + \"|\" + date_str + \"|\" + comp_str\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2) DIM TEAM\n",
    "# =====================================================\n",
    "\n",
    "teams_gps = pd.concat(\n",
    "    [matches_gps[\"team_name\"], training_gps[\"team_name\"]],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "teams_wys = pd.concat(\n",
    "    [wys_matches[\"team_name\"], wys_gk[\"team_name\"], wys_outfield[\"team_name\"]],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "all_team_names = (\n",
    "    pd.concat([teams_gps, teams_wys], ignore_index=True)\n",
    "      .dropna()\n",
    "      .drop_duplicates()\n",
    "      .sort_values()\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "dim_team = pd.DataFrame({\"team_name_std\": all_team_names})\n",
    "dim_team[\"team_key\"] = np.arange(1, len(dim_team) + 1)\n",
    "\n",
    "dim_team[\"team_name_gps\"] = np.where(\n",
    "    dim_team[\"team_name_std\"].isin(teams_gps.dropna().unique()),\n",
    "    dim_team[\"team_name_std\"],\n",
    "    pd.NA,\n",
    ")\n",
    "dim_team[\"team_name_wyscout\"] = np.where(\n",
    "    dim_team[\"team_name_std\"].isin(teams_wys.dropna().unique()),\n",
    "    dim_team[\"team_name_std\"],\n",
    "    pd.NA,\n",
    ")\n",
    "\n",
    "dim_team[\"image_url\"]        = pd.NA\n",
    "dim_team[\"image_url_no_bg\"]  = pd.NA\n",
    "dim_team[\"image_source\"]     = pd.NA\n",
    "dim_team[\"created_at\"]       = pd.Timestamp.utcnow().normalize()\n",
    "\n",
    "dim_team = dim_team[\n",
    "    [\n",
    "        \"team_key\",\n",
    "        \"team_name_std\",\n",
    "        \"team_name_gps\",\n",
    "        \"team_name_wyscout\",\n",
    "        \"image_url\",\n",
    "        \"image_url_no_bg\",\n",
    "        \"image_source\",\n",
    "        \"created_at\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "team_key_by_name = dict(zip(dim_team[\"team_name_std\"], dim_team[\"team_key\"]))\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3) DIM PLAYER\n",
    "# =====================================================\n",
    "\n",
    "# noms depuis Wyscout (GK + outfield)\n",
    "wys_players_raw = pd.concat(\n",
    "    [\n",
    "        wys_gk[[\"player\", \"team_name\"]],\n",
    "        wys_outfield[[\"player\", \"team_name\"]],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ").dropna(subset=[\"player\"])\n",
    "\n",
    "wys_players_raw = wys_players_raw.drop_duplicates(subset=[\"player\"])\n",
    "\n",
    "# noms depuis GPS\n",
    "gps_players_raw = pd.concat(\n",
    "    [\n",
    "        matches_gps[[\"name\", \"team_name\"]].rename(columns={\"name\": \"player\"}),\n",
    "        training_gps[[\"name\", \"team_name\"]].rename(columns={\"name\": \"player\"}),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ").dropna(subset=[\"player\"])\n",
    "\n",
    "players_all = pd.concat([wys_players_raw, gps_players_raw], ignore_index=True)\n",
    "players_all = (\n",
    "    players_all.sort_values([\"player\", \"team_name\"])\n",
    "               .drop_duplicates(subset=[\"player\"], keep=\"first\")\n",
    "               .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "dim_player = pd.DataFrame()\n",
    "dim_player[\"player_key\"]         = np.arange(1, len(players_all) + 1)\n",
    "dim_player[\"player_name_std\"]    = players_all[\"player\"]\n",
    "dim_player[\"player_name_gps\"]    = np.where(\n",
    "    dim_player[\"player_name_std\"].isin(gps_players_raw[\"player\"].unique()),\n",
    "    dim_player[\"player_name_std\"],\n",
    "    pd.NA,\n",
    ")\n",
    "dim_player[\"player_name_wyscout\"] = np.where(\n",
    "    dim_player[\"player_name_std\"].isin(wys_players_raw[\"player\"].unique()),\n",
    "    dim_player[\"player_name_std\"],\n",
    "    pd.NA,\n",
    ")\n",
    "dim_player[\"player_name_sportdb\"] = pd.NA\n",
    "\n",
    "dim_player[\"team_key\"] = players_all[\"team_name\"].map(team_key_by_name)\n",
    "\n",
    "dim_player[\"image_url\"]        = pd.NA\n",
    "dim_player[\"image_url_no_bg\"]  = pd.NA\n",
    "dim_player[\"image_source\"]     = pd.NA\n",
    "dim_player[\"created_at\"]       = pd.Timestamp.utcnow().normalize()\n",
    "\n",
    "dim_player = dim_player[\n",
    "    [\n",
    "        \"player_key\",\n",
    "        \"player_name_std\",\n",
    "        \"player_name_gps\",\n",
    "        \"player_name_wyscout\",\n",
    "        \"player_name_sportdb\",\n",
    "        \"team_key\",\n",
    "        \"image_url\",\n",
    "        \"image_url_no_bg\",\n",
    "        \"image_source\",\n",
    "        \"created_at\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "player_key_by_name = dict(zip(dim_player[\"player_name_std\"], dim_player[\"player_key\"]))\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4) DIM COMPETITION\n",
    "# =====================================================\n",
    "\n",
    "competitions = pd.concat(\n",
    "    [wys_matches[\"competition\"], wys_gk[\"competition\"], wys_outfield[\"competition\"]],\n",
    "    ignore_index=True,\n",
    ").dropna().drop_duplicates().sort_values()\n",
    "\n",
    "dim_competition = pd.DataFrame({\"competition_name_std\": competitions})\n",
    "dim_competition[\"competition_key\"] = np.arange(1, len(dim_competition) + 1)\n",
    "\n",
    "dim_competition[\"competition_name_gps\"]      = pd.NA\n",
    "dim_competition[\"competition_name_wyscout\"]  = dim_competition[\"competition_name_std\"]\n",
    "dim_competition[\"competition_name_sportdb\"]  = pd.NA\n",
    "dim_competition[\"created_at\"]                = pd.Timestamp.utcnow().normalize()\n",
    "\n",
    "dim_competition = dim_competition[\n",
    "    [\n",
    "        \"competition_key\",\n",
    "        \"competition_name_std\",\n",
    "        \"competition_name_gps\",\n",
    "        \"competition_name_wyscout\",\n",
    "        \"competition_name_sportdb\",\n",
    "        \"created_at\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "comp_key_by_name = dict(\n",
    "    zip(dim_competition[\"competition_name_std\"], dim_competition[\"competition_key\"])\n",
    ")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 5) DIM DATE\n",
    "# =====================================================\n",
    "\n",
    "all_dates_raw = pd.concat(\n",
    "    [\n",
    "        matches_gps[\"date\"],\n",
    "        training_gps[\"date\"],\n",
    "        wys_matches[\"date\"],\n",
    "        wys_gk[\"date\"],\n",
    "        wys_outfield[\"date\"],\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "all_dates = parse_date_col(all_dates_raw)\n",
    "all_dates = (\n",
    "    all_dates.dropna()\n",
    "    .drop_duplicates()\n",
    "    .sort_values()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "dim_date = pd.DataFrame({\"date\": all_dates})\n",
    "dim_date[\"date_key\"]     = dim_date[\"date\"].dt.strftime(\"%Y%m%d\").astype(int)\n",
    "dim_date[\"year\"]         = dim_date[\"date\"].dt.year\n",
    "dim_date[\"quarter\"]      = dim_date[\"date\"].dt.quarter\n",
    "dim_date[\"month\"]        = dim_date[\"date\"].dt.month\n",
    "dim_date[\"month_name\"]   = dim_date[\"date\"].dt.month_name()\n",
    "dim_date[\"week_of_year\"] = dim_date[\"date\"].dt.isocalendar().week.astype(int)\n",
    "dim_date[\"day\"]          = dim_date[\"date\"].dt.day\n",
    "dim_date[\"day_of_week\"]  = dim_date[\"date\"].dt.weekday + 1\n",
    "dim_date[\"day_name\"]     = dim_date[\"date\"].dt.day_name()\n",
    "dim_date[\"is_weekend\"]   = dim_date[\"day_of_week\"].isin([6, 7])\n",
    "\n",
    "year  = dim_date[\"year\"]\n",
    "month = dim_date[\"month\"]\n",
    "dim_date[\"season\"] = np.where(\n",
    "    month >= 7,\n",
    "    year.astype(str) + \"-\" + (year + 1).astype(str),\n",
    "    (year - 1).astype(str) + \"-\" + year.astype(str),\n",
    ")\n",
    "\n",
    "dim_date[\"created_at\"] = pd.Timestamp.utcnow().normalize()\n",
    "\n",
    "dim_date = dim_date[\n",
    "    [\n",
    "        \"date_key\",\n",
    "        \"date\",\n",
    "        \"year\",\n",
    "        \"quarter\",\n",
    "        \"month\",\n",
    "        \"month_name\",\n",
    "        \"week_of_year\",\n",
    "        \"day\",\n",
    "        \"day_of_week\",\n",
    "        \"day_name\",\n",
    "        \"is_weekend\",\n",
    "        \"season\",\n",
    "        \"created_at\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "date_key_by_date = dict(zip(dim_date[\"date\"], dim_date[\"date_key\"]))\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6) FACT PLAYER WYSCOUT (construit AVANT dim_match)\n",
    "#    => puis dim_match déduite des players\n",
    "# =====================================================\n",
    "\n",
    "wys_gk[\"position_type\"]       = \"GK\"\n",
    "wys_outfield[\"position_type\"] = \"OUTFIELD\"\n",
    "\n",
    "players_wys_all = pd.concat([wys_gk, wys_outfield], ignore_index=True, sort=False)\n",
    "\n",
    "players_wys_all[\"match_date\"] = parse_date_col(players_wys_all[\"date\"])\n",
    "players_wys_all[\"date_key\"]   = players_wys_all[\"match_date\"].map(date_key_by_date)\n",
    "players_wys_all[\"team_key\"]   = players_wys_all[\"team_name\"].map(team_key_by_name)\n",
    "players_wys_all[\"player_key\"] = players_wys_all[\"player\"].map(player_key_by_name)\n",
    "players_wys_all[\"competition_key\"] = players_wys_all[\"competition\"].map(comp_key_by_name)\n",
    "\n",
    "# match_uid basé SUR LES PLAYERS\n",
    "players_wys_all[\"match_uid\"] = make_match_uid(players_wys_all)\n",
    "\n",
    "# =====================================================\n",
    "# 7) DIM MATCH basé sur players_wys_all, enrichi par wys_matches\n",
    "# =====================================================\n",
    "\n",
    "# base : toutes les combinaisons (match, date, competition) qu'on voit chez les joueurs\n",
    "match_dim_raw = (\n",
    "    players_wys_all[[\"match_uid\", \"match_date\", \"match\", \"competition\"]]\n",
    "    .drop_duplicates(subset=[\"match_uid\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# essayer d'enrichir avec score / equipe / adversaire depuis wys_matches\n",
    "wys_matches = wys_matches.copy()\n",
    "wys_matches[\"match_uid\"] = make_match_uid(wys_matches)\n",
    "\n",
    "match_extra = (\n",
    "    wys_matches[[\"match_uid\", \"score\", \"equipe\", \"adversaire\"]]\n",
    "    .drop_duplicates(subset=[\"match_uid\"])\n",
    ")\n",
    "\n",
    "match_dim_raw = match_dim_raw.merge(\n",
    "    match_extra,\n",
    "    on=\"match_uid\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "dim_match = pd.DataFrame()\n",
    "dim_match[\"match_key\"]       = np.arange(1, len(match_dim_raw) + 1)\n",
    "dim_match[\"match_date\"]      = match_dim_raw[\"match_date\"]\n",
    "dim_match[\"competition_key\"] = match_dim_raw[\"competition\"].map(comp_key_by_name)\n",
    "dim_match[\"date_key\"]        = match_dim_raw[\"match_date\"].map(date_key_by_date)\n",
    "dim_match[\"score\"]           = match_dim_raw[\"score\"]\n",
    "\n",
    "# home/away si on a pu les récupérer (sinon NaN)\n",
    "dim_match[\"home_team_key\"] = match_dim_raw[\"equipe\"].map(team_key_by_name)\n",
    "dim_match[\"away_team_key\"] = match_dim_raw[\"adversaire\"].map(team_key_by_name)\n",
    "\n",
    "# saison depuis dim_date\n",
    "dim_match = dim_match.merge(\n",
    "    dim_date[[\"date_key\", \"season\"]],\n",
    "    on=\"date_key\",\n",
    "    how=\"left\",\n",
    ")\n",
    "dim_match.rename(columns={\"season\": \"season\"}, inplace=True)\n",
    "\n",
    "gps_match_dates = parse_date_col(matches_gps[\"date\"]).dropna().unique()\n",
    "dim_match[\"has_gps_data\"]     = dim_match[\"match_date\"].isin(gps_match_dates)\n",
    "dim_match[\"has_wyscout_data\"] = True\n",
    "dim_match[\"has_sportdb_data\"] = False\n",
    "dim_match[\"created_at\"]       = pd.Timestamp.utcnow().normalize()\n",
    "\n",
    "dim_match = dim_match[\n",
    "    [\n",
    "        \"match_key\",\n",
    "        \"match_date\",\n",
    "        \"home_team_key\",\n",
    "        \"away_team_key\",\n",
    "        \"competition_key\",\n",
    "        \"date_key\",\n",
    "        \"score\",\n",
    "        \"season\",\n",
    "        \"has_gps_data\",\n",
    "        \"has_wyscout_data\",\n",
    "        \"has_sportdb_data\",\n",
    "        \"created_at\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# mapping match_uid -> match_key basé sur LES PLAYERS\n",
    "match_key_by_uid = dict(zip(match_dim_raw[\"match_uid\"], dim_match[\"match_key\"]))\n",
    "\n",
    "# maintenant on peut remplir match_key dans players_wys_all\n",
    "players_wys_all[\"match_key\"] = players_wys_all[\"match_uid\"].map(match_key_by_uid)\n",
    "\n",
    "print(\"\\n[DEBUG] Proportion de match_key NaN dans players_wys_all :\",\n",
    "      players_wys_all[\"match_key\"].isna().mean())\n",
    "\n",
    "fact_player_wyscout = players_wys_all.reset_index(drop=True)\n",
    "fact_player_wyscout.insert(0, \"fact_player_wyscout_key\", fact_player_wyscout.index + 1)\n",
    "fact_player_wyscout = fact_player_wyscout.drop(columns=[\"match_uid\"])\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 8) FACT MATCH WYSCOUT (agrégé à partir de wys_matches)\n",
    "# =====================================================\n",
    "\n",
    "fact_match_wyscout = wys_matches.copy()\n",
    "\n",
    "fact_match_wyscout[\"match_date\"] = parse_date_col(fact_match_wyscout[\"date\"])\n",
    "fact_match_wyscout[\"date_key\"]   = fact_match_wyscout[\"match_date\"].map(date_key_by_date)\n",
    "fact_match_wyscout[\"team_key\"]   = fact_match_wyscout[\"team_name\"].map(team_key_by_name)\n",
    "fact_match_wyscout[\"opponent_team_key\"] = fact_match_wyscout[\"adversaire\"].map(team_key_by_name)\n",
    "fact_match_wyscout[\"competition_key\"]   = fact_match_wyscout[\"competition\"].map(comp_key_by_name)\n",
    "\n",
    "fact_match_wyscout[\"match_uid\"] = make_match_uid(fact_match_wyscout)\n",
    "fact_match_wyscout[\"match_key\"] = fact_match_wyscout[\"match_uid\"].map(match_key_by_uid)\n",
    "\n",
    "fact_match_wyscout = fact_match_wyscout.reset_index(drop=True)\n",
    "fact_match_wyscout.insert(0, \"fact_match_wyscout_key\", fact_match_wyscout.index + 1)\n",
    "fact_match_wyscout = fact_match_wyscout.drop(columns=[\"match_uid\"])\n",
    "\n",
    "print(\"[DEBUG] Proportion de match_key NaN dans fact_match_wyscout :\",\n",
    "      fact_match_wyscout[\"match_key\"].isna().mean())\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 9) FACT PLAYER GPS (match + training)\n",
    "# =====================================================\n",
    "\n",
    "matches_gps2  = matches_gps.copy()\n",
    "training_gps2 = training_gps.copy()\n",
    "\n",
    "matches_gps2[\"session_type\"]  = \"match\"\n",
    "training_gps2[\"session_type\"] = \"training\"\n",
    "\n",
    "gps_all = pd.concat([matches_gps2, training_gps2], ignore_index=True, sort=False)\n",
    "\n",
    "gps_all[\"session_date\"] = parse_date_col(gps_all[\"date\"])\n",
    "gps_all[\"date_key\"]     = gps_all[\"session_date\"].map(date_key_by_date)\n",
    "gps_all[\"team_key\"]     = gps_all[\"team_name\"].map(team_key_by_name)\n",
    "gps_all[\"player_key\"]   = gps_all[\"name\"].map(player_key_by_name)\n",
    "\n",
    "# pour l'instant, pas de lien direct avec dim_match\n",
    "gps_all[\"match_key\"] = pd.NA\n",
    "\n",
    "fact_player_gps = gps_all.reset_index(drop=True)\n",
    "fact_player_gps.insert(0, \"fact_player_gps_key\", fact_player_gps.index + 1)\n",
    "\n",
    "protected_cols = {\n",
    "    \"fact_player_gps_key\",\n",
    "    \"player_key\",\n",
    "    \"team_key\",\n",
    "    \"match_key\",\n",
    "    \"date_key\",\n",
    "    \"session_type\",\n",
    "    \"session_date\",\n",
    "}\n",
    "gps_cols_renamed = {\n",
    "    c: slugify(c)\n",
    "    for c in fact_player_gps.columns\n",
    "    if c not in protected_cols\n",
    "}\n",
    "fact_player_gps = fact_player_gps.rename(columns=gps_cols_renamed)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 10) Sauvegarde des CSV star_schema\n",
    "# =====================================================\n",
    "\n",
    "dim_team.to_csv(OUT_DIR / \"dim_team.csv\", index=False)\n",
    "dim_player.to_csv(OUT_DIR / \"dim_player.csv\", index=False)\n",
    "dim_competition.to_csv(OUT_DIR / \"dim_competition.csv\", index=False)\n",
    "dim_date.to_csv(OUT_DIR / \"dim_date.csv\", index=False)\n",
    "dim_match.to_csv(OUT_DIR / \"dim_match.csv\", index=False)\n",
    "\n",
    "fact_match_wyscout.to_csv(OUT_DIR / \"fact_match_wyscout.csv\", index=False)\n",
    "fact_player_wyscout.to_csv(OUT_DIR / \"fact_player_wyscout.csv\", index=False)\n",
    "fact_player_gps.to_csv(OUT_DIR / \"fact_player_gps.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ Fichiers star_schema écrits dans :\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "524fbbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT_DIR = CSV\\star_schema\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"CSV\")          # si tes fichiers sont dans ./CSV\n",
    "OUT_DIR = DATA_DIR / \"star_schema\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"OUT_DIR =\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ec4ef0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion de match_key NaN : 0.0\n",
      "                                       match        date  \\\n",
      "0                  Aston Villa - Chelsea 1:3  2021-12-26   \n",
      "1          Benfica U23 - Sporting CP U23 1:1  2018-12-04   \n",
      "2                          Nice - Rennes 1:1  2020-01-24   \n",
      "3       Nice II - Olympique Marseille II 2:1  2016-04-30   \n",
      "4                 Sporting CP - Boavista 2:0  2020-02-23   \n",
      "5  Paços de Ferreira - Vitória Guimarães 0:1  2022-10-08   \n",
      "6          Vitória Guimarães - Famalicão 3:2  2022-10-31   \n",
      "7                     Montpellier - Nice 0:0  2023-11-10   \n",
      "8                      Sporting CP - PSV 4:0  2019-11-28   \n",
      "9                 Chelsea U19 - Roma U19 0:2  2017-10-18   \n",
      "\n",
      "                       competition  match_key  \n",
      "0          England. Premier League          1  \n",
      "1  Portugal. Liga Revelação Sub 23          2  \n",
      "2                  France. Ligue 1          3  \n",
      "3               France. National 2          4  \n",
      "4          Portugal. Primeira Liga          5  \n",
      "5          Portugal. Primeira Liga          6  \n",
      "6          Portugal. Primeira Liga          7  \n",
      "7                  France. Ligue 1          8  \n",
      "8       Europe. UEFA Europa League          9  \n",
      "9        Europe. UEFA Youth League         10  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "OUT_DIR = Path(\"CSV\") / \"star_schema\"\n",
    "fpw = pd.read_csv(OUT_DIR / \"fact_player_wyscout.csv\", low_memory=False)\n",
    "\n",
    "print(\"Proportion de match_key NaN :\", fpw[\"match_key\"].isna().mean())\n",
    "print(fpw[[\"match\", \"date\", \"competition\", \"match_key\"]].head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
